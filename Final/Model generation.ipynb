{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dfe7c3",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee21da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "\n",
    "from random import sample\n",
    "\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "    \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import load_img, image_dataset_from_directory, img_to_array\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from keras.applications.vgg19 import VGG19 \n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc31449",
   "metadata": {},
   "source": [
    "## Model generation\n",
    "\n",
    "#### Adapted from https://franky07724-57962.medium.com/using-keras-pre-trained-models-for-feature-extraction-in-image-clustering-a142c6cdf5b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f17c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from folder\n",
    "\n",
    "def load_images(image_directory):\n",
    "\n",
    "    images_list = []\n",
    "    \n",
    "    with os.scandir(image_directory) as files:\n",
    "        for file in files:\n",
    "            if file.name.endswith('.png'):\n",
    "                images_list.append(file.name)\n",
    "                \n",
    "    if os.path.exists('data')==False:\n",
    "        os.makedirs('data')\n",
    "    pd.DataFrame(images_list).to_csv('data/images_list.csv', index=True)\n",
    "    \n",
    "    return images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract features from the images\n",
    "\n",
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    \n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "    \n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    \n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4360d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a vgg model to extract features from images\n",
    "\n",
    "def vgg_model(image_directory, images_list, model, model_name):\n",
    "    if os.path.exists('model')==False:\n",
    "        os.makedirs('model')\n",
    "    \n",
    "    vgg_model = model()\n",
    "    vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)\n",
    "\n",
    "    data = {}\n",
    "    #p = filepath\n",
    "\n",
    "    # loop through each image in the dataset\n",
    "    for image in progress_bar(images_list):\n",
    "        # try to extract the features and update the dictionary\n",
    "        try:\n",
    "            feature = extract_features(f'{image_directory}/{image}', vgg_model)\n",
    "            data[image] = feature\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "        except:\n",
    "            print('except')\n",
    "            with open('model','wb') as file:\n",
    "                pickle.dump(data, file)\n",
    "    model_features = np.array(list(data.values()))\n",
    "    model_features = model_features.reshape(-1,4096)\n",
    "    \n",
    "    pd.DataFrame(model_features).to_csv(f'model/{model_name}_features.csv', index=False)\n",
    "    \n",
    "    with open(f\"model/{model_name}_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(vgg_model, f)\n",
    "    \n",
    "    return model_features #,model_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e8958",
   "metadata": {},
   "source": [
    "## Clustering and cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use PCA to reduce number of features\n",
    "# plot explained variance to choose number of components for future analysis\n",
    "\n",
    "def model_pca_components(model_features, model_name):\n",
    "    pca = PCA(n_components=100, random_state=22)\n",
    "    pca_features = pca.fit_transform(model_features)\n",
    "\n",
    "    fig = plt.plot(pca.explained_variance_ratio_)\n",
    "    plt.xlabel(\"Principal Component\")\n",
    "    plt.ylabel(\"Variance\")\n",
    "    plt.title('VGG19 PCA Explained Variance')\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.savefig(f'model/{model_name}_pca_variance.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract PCA features using minimum number of components\n",
    "\n",
    "def extract_pca_features(model_features, model_name, n_components=20):\n",
    "    pca = PCA(n_components=n_components, random_state=22)\n",
    "    pca_features = pca.fit_transform(model_features)\n",
    "    \n",
    "    if os.path.exists('model')==False:\n",
    "        os.makedirs('model')\n",
    "    pd.DataFrame(pca_features).to_csv(f'model/{model_name}_pca_features.csv', index=False)\n",
    "    \n",
    "    return pca_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaac51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to see which value for k might be the best \n",
    "\n",
    "def n_cluster_analysis(min_k, max_k, pca_features, model_name):\n",
    "    sse = []\n",
    "    list_k = list(range(min_k, max_k))\n",
    "\n",
    "    for k in list_k:\n",
    "        km = KMeans(n_init = 'auto', n_clusters=k, random_state=22)\n",
    "        km.fit(pca_features)\n",
    "    \n",
    "        sse.append(km.inertia_)\n",
    "\n",
    "    # Plot sse against k\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(list_k, sse)\n",
    "    plt.xlabel(r'Number of clusters *k*')\n",
    "    plt.ylabel('Sum of squared distance')\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    \n",
    "    if os.path.exists('model')==False:\n",
    "        os.makedirs('model')\n",
    "    plt.savefig(f'model/{model_name}_kmeans_inertia.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#\n",
    "# plot silhouette graphs to analyze and choose the proper number of clusters\n",
    "\n",
    "def silhouette_analysis(pca_features, model_name, range_n_clusters):\n",
    "\n",
    "    X = pca_features\n",
    "    range_n_clusters = range_n_clusters\n",
    "    kmeans_dict = {}\n",
    "\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Create a subplot with 1 row and 2 columns\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(18, 7)\n",
    "\n",
    "        # The 1st subplot is the silhouette plot\n",
    "        # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "        # lie within [-0.1, 1]\n",
    "        ax1.set_xlim([-0.1, 1])\n",
    "        # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "        # plots of individual clusters, to demarcate them clearly.\n",
    "        ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "        clusterer = KMeans(n_clusters=n_clusters, n_init=\"auto\", random_state=22)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "        \n",
    "        if os.path.exists('model')==False:\n",
    "            os.makedirs('model')\n",
    "        pd.DataFrame(cluster_labels).to_csv(f'model/{model_name}_kmeans{n_clusters}.csv', index=False)       \n",
    "\n",
    "        kmeans_dict[n_clusters] = cluster_labels\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "        print(\n",
    "            \"For n_clusters =\",\n",
    "            n_clusters,\n",
    "            \"The average silhouette_score is :\",\n",
    "            silhouette_avg,\n",
    "        )\n",
    "\n",
    "        # Compute the silhouette scores for each sample\n",
    "        sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            # Aggregate the silhouette scores for samples belonging to\n",
    "            # cluster i, and sort them\n",
    "            ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "            ax1.fill_betweenx(\n",
    "                np.arange(y_lower, y_upper),\n",
    "                0,\n",
    "                ith_cluster_silhouette_values,\n",
    "                facecolor=color,\n",
    "                edgecolor=color,\n",
    "                alpha=0.7,\n",
    "            )\n",
    "\n",
    "            # Label the silhouette plots with their cluster numbers at the middle\n",
    "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "            # Compute the new y_lower for next plot\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "        ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "        ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "        ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "        # The vertical line for average silhouette score of all the values\n",
    "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        # 2nd Plot showing the actual clusters formed\n",
    "        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "        ax2.scatter(\n",
    "            X[:, 0], X[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "        )\n",
    "\n",
    "        # Labeling the clusters\n",
    "        centers = clusterer.cluster_centers_\n",
    "        # Draw white circles at cluster centers\n",
    "        ax2.scatter(\n",
    "            centers[:, 0],\n",
    "            centers[:, 1],\n",
    "            marker=\"o\",\n",
    "            c=\"white\",\n",
    "            alpha=1,\n",
    "            s=200,\n",
    "            edgecolor=\"k\",\n",
    "        )\n",
    "\n",
    "        for i, c in enumerate(centers):\n",
    "            ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "        ax2.set_title(\"The visualization of the clustered data.\")\n",
    "        ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "        ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "            % n_clusters,\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        plt.savefig(f'model/{model_name}_kmeans{n_clusters}_silhouette.png', bbox_inches='tight')\n",
    "        \n",
    "    return kmeans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b72f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display samples of each cluster to ensure proper groupings and to be able to assign grade label\n",
    "\n",
    "def display_image_clusters(kmeans_dict, model_name, images_list):\n",
    "    \n",
    "    for n_cluster in kmeans_dict.keys():\n",
    "        print(\"Number of clusters: \", n_cluster)\n",
    "        groups = {}\n",
    "        \n",
    "        for file, cluster in zip(images_list, kmeans_dict[n_cluster]):\n",
    "            if cluster not in groups.keys():\n",
    "                groups[cluster] = []\n",
    "                groups[cluster].append(file)\n",
    "            else:\n",
    "                groups[cluster].append(file)\n",
    "\n",
    "        for cluster in range(len(groups)):\n",
    "            print(\"Cluster: \", cluster)\n",
    "            plt.figure(figsize = (25,25));\n",
    "\n",
    "            # gets the list of filenames for a cluster\n",
    "            files = groups[cluster]\n",
    "\n",
    "            # only allow up to 100 images to be shown at a time\n",
    "            if len(files) > 100:\n",
    "                files = sample(files,100)\n",
    "\n",
    "            # plot each image in the cluster\n",
    "            for index, file in enumerate(files):\n",
    "                plt.subplot(10,20,index+1);\n",
    "                img = load_img(f'images/{file}')\n",
    "                img = np.array(img)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "                \n",
    "            if os.path.exists('model')==False:\n",
    "                os.makedirs('model')\n",
    "            plt.savefig(f'model/{model_name}_kmeans{n_cluster}_cluster{cluster}.png', bbox_inches='tight')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56685f98",
   "metadata": {},
   "source": [
    "## Make VGG19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = load_images(image_directory='images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = vgg_model(image_directory='images', images_list=images_list, model=VGG19, model_name='VGG19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ab763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca_components(model_features=model_features, model_name='VGG19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = extract_pca_features(model_features=model_features, model_name='VGG19', n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster_analysis(min_k=3, max_k=50, pca_features=pca_features, model_name='VGG19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed648d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_dict = silhouette_analysis(pca_features=pca_features, model_name='VGG19', range_n_clusters=[10, 20, 30, 40, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_clusters(kmeans_dict=kmeans_dict, model_name='VGG19', images_list=images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55576e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad5e1bd7",
   "metadata": {},
   "source": [
    "## Make VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff572b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = vgg_model(image_directory='images', images_list=images_list, model=VGG16, model_name='VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca_components(model_features=model_features, model_name='VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a1976",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = extract_pca_features(model_features=model_features, model_name='VGG16', n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster_analysis(min_k=3, max_k=50, pca_features=pca_features, model_name='VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_dict = silhouette_analysis(pca_features=pca_features, model_name='VGG16', range_n_clusters=[10, 20, 30, 40, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe8aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_clusters(kmeans_dict=kmeans_dict, model_name='VGG16', images_list=images_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b56dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonDS v1.2",
   "language": "python",
   "name": "py_v1.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
